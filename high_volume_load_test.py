import asyncio
import aiohttp
import time
from datetime import datetime
import json

class HighVolumeLoadTester:
    def __init__(self, api_url="http://localhost:8000"):
        self.api_url = api_url
        self.results = []
        
    async def send_async_request(self, session, request_id):
        """ë¹„ë™ê¸° ìš”ì²­ ì „ì†¡"""
        start_time = time.time()
        try:
            async with session.get(f"{self.api_url}/") as response:
                response_time = time.time() - start_time
                return {
                    "id": request_id,
                    "status": response.status,
                    "response_time": response_time,
                    "timestamp": time.time(),
                    "success": True
                }
        except Exception as e:
            response_time = time.time() - start_time
            return {
                "id": request_id,
                "error": str(e),
                "response_time": response_time,
                "timestamp": time.time(),
                "success": False
            }
    
    async def massive_load_test(self, total_requests=10000, concurrent_limit=200):
        """ëŒ€ìš©ëŸ‰ ë¶€í•˜í…ŒìŠ¤íŠ¸ (10,000+ ìš”ì²­)"""
        print(f"ğŸ”¥ ëŒ€ìš©ëŸ‰ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"   ì´ ìš”ì²­: {total_requests:,}")
        print(f"   ìµœëŒ€ ë™ì‹œì„±: {concurrent_limit}")
        print(f"   ì‹œì‘ ì‹œê°„: {datetime.now()}")
        
        start_time = time.time()
        semaphore = asyncio.Semaphore(concurrent_limit)
        
        async def limited_request(session, request_id):
            async with semaphore:
                return await self.send_async_request(session, request_id)
        
        # ì»¤ë„¥ì…˜ í’€ ìµœì í™”
        connector = aiohttp.TCPConnector(
            limit=500,  # ì´ ì—°ê²° ìˆ˜
            limit_per_host=200,  # í˜¸ìŠ¤íŠ¸ë‹¹ ì—°ê²° ìˆ˜
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(total=30)
        
        async with aiohttp.ClientSession(
            connector=connector, 
            timeout=timeout
        ) as session:
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìš”ì²­ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            batch_size = 1000
            all_results = []
            
            for batch_start in range(0, total_requests, batch_size):
                batch_end = min(batch_start + batch_size, total_requests)
                batch_requests = range(batch_start, batch_end)
                
                print(f"   ë°°ì¹˜ ì²˜ë¦¬: {batch_start:,} - {batch_end:,}")
                
                tasks = [limited_request(session, i) for i in batch_requests]
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ì˜ˆì™¸ ì²˜ë¦¬
                valid_results = []
                for result in batch_results:
                    if isinstance(result, dict):
                        valid_results.append(result)
                    else:
                        valid_results.append({
                            "error": str(result),
                            "success": False,
                            "timestamp": time.time()
                        })
                
                all_results.extend(valid_results)
                
                # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì¤‘ê°„ ë¶„ì„
                if len(all_results) % 5000 == 0:
                    self.print_interim_stats(all_results, start_time)
        
        end_time = time.time()
        
        # ìµœì¢… ë¶„ì„
        self.analyze_massive_results(all_results, end_time - start_time)
        return all_results
    
    def print_interim_stats(self, results, start_time):
        """ì¤‘ê°„ í†µê³„ ì¶œë ¥"""
        successful = [r for r in results if r.get("success", False)]
        elapsed = time.time() - start_time
        
        print(f"   ì¤‘ê°„ í†µê³„: {len(successful):,}/{len(results):,} ì„±ê³µ, "
              f"í‰ê·  {len(successful)/elapsed:.1f} req/sec")
    
    def analyze_massive_results(self, results, total_duration):
        """ëŒ€ìš©ëŸ‰ ê²°ê³¼ ë¶„ì„"""
        successful_requests = [r for r in results if r.get("success", False)]
        failed_requests = [r for r in results if not r.get("success", False)]
        
        print(f"\nğŸ“Š ëŒ€ìš©ëŸ‰ ë¶€í•˜í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   ì´ ìš”ì²­: {len(results):,}")
        print(f"   ì„±ê³µ: {len(successful_requests):,}")
        print(f"   ì‹¤íŒ¨: {len(failed_requests):,}")
        print(f"   ì„±ê³µë¥ : {len(successful_requests)/len(results)*100:.1f}%")
        print(f"   ì´ ì†Œìš” ì‹œê°„: {total_duration:.1f}ì´ˆ")
        print(f"   í‰ê·  ì²˜ë¦¬ëŸ‰: {len(successful_requests)/total_duration:.1f} req/sec")
        
        if successful_requests:
            response_times = [r.get("response_time", 0) for r in successful_requests]
            response_times.sort()
            
            print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„ ë¶„ì„:")
            print(f"   í‰ê· : {sum(response_times)/len(response_times):.3f}ì´ˆ")
            print(f"   ì¤‘ì•™ê°’: {response_times[len(response_times)//2]:.3f}ì´ˆ")
            print(f"   P95: {response_times[int(len(response_times)*0.95)]:.3f}ì´ˆ")
            print(f"   P99: {response_times[int(len(response_times)*0.99)]:.3f}ì´ˆ")
            print(f"   ìµœëŒ€: {max(response_times):.3f}ì´ˆ")
        
        # ì‹œê°„ëŒ€ë³„ ì²˜ë¦¬ëŸ‰ ë¶„ì„ (10ì´ˆ ë‹¨ìœ„)
        if successful_requests:
            self.analyze_throughput_over_time(successful_requests, total_duration)
    
    def analyze_throughput_over_time(self, successful_requests, total_duration):
        """ì‹œê°„ëŒ€ë³„ ì²˜ë¦¬ëŸ‰ ë¶„ì„"""
        print(f"\nğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì²˜ë¦¬ëŸ‰ ë¶„ì„ (10ì´ˆ ë‹¨ìœ„):")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ê·œí™”
        min_time = min(r["timestamp"] for r in successful_requests)
        time_buckets = {}
        
        for request in successful_requests:
            bucket = int((request["timestamp"] - min_time) // 10) * 10
            time_buckets[bucket] = time_buckets.get(bucket, 0) + 1
        
        for second in sorted(time_buckets.keys())[:10]:  # ì²˜ìŒ 100ì´ˆë§Œ í‘œì‹œ
            throughput = time_buckets[second] / 10  # 10ì´ˆ í‰ê· 
            print(f"   {second:3d}-{second+9:3d}ì´ˆ: {throughput:6.1f} req/sec ({time_buckets[second]:,}ê°œ)")

# ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
async def run_high_volume_scenarios():
    """ë‹¤ì–‘í•œ ëŒ€ìš©ëŸ‰ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    tester = HighVolumeLoadTester()
    
    scenarios = [
        {"name": "ì¤‘ê°„ ê·œëª¨", "requests": 5000, "concurrent": 100},
        {"name": "ëŒ€ê·œëª¨", "requests": 10000, "concurrent": 150},
        {"name": "ì´ˆëŒ€ê·œëª¨", "requests": 20000, "concurrent": 200},
        {"name": "ê·¹í•œ í…ŒìŠ¤íŠ¸", "requests": 50000, "concurrent": 300}
    ]
    
    for scenario in scenarios:
        print(f"\n{'='*80}")
        print(f"ğŸ§ª ì‹œë‚˜ë¦¬ì˜¤: {scenario['name']}")
        
        try:
            await tester.massive_load_test(
                scenario['requests'], 
                scenario['concurrent']
            )
        except Exception as e:
            print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤íŒ¨: {e}")
        
        print("\nâ³ ì‹œìŠ¤í…œ ì•ˆì •í™” ëŒ€ê¸° ì¤‘ (30ì´ˆ)...")
        await asyncio.sleep(30)

if __name__ == "__main__":
    asyncio.run(run_high_volume_scenarios())
